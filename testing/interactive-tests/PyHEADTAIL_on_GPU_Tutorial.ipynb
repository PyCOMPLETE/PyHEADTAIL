{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use PyHEADTAIL on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will show you how to use the GPU functionality of PyHEADTAIL. Created on 19. Feb 2016, Stefan Hegglin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the GPU module, you will need the following:\n",
    "    - A Nvidia GPU: Tested on Tesla C2075 and Kepler K20\n",
    "    - CUDA version >6.5\n",
    "    - PyCUDA version 2015.1.3. Earlier versions possible but are not tested.\n",
    "    - scikit-cuda 0.5.1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Setup\n",
    "In order to use the GPU, initialise it via the following statement. If it fails, this means the GPU or pycuda was not setup correctly. [This could also be performed automatically inside the context module, however it is less safe since we do not know what happens if the user creates another context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pycuda.autoinit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The usual imports: numpy, matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.constants import c, e, m_p\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add PyHEADTAIL to the path. If you run this notebook from within the PyHEADTAIL/testing/interactive-tests folder, the following should work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('../../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the GPU and CPU contextmanagers and the PyHEADTAIL BasicSynchrotron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PyHEADTAIL.machines.synchrotron import BasicSynchrotron\n",
    "from PyHEADTAIL.general.contextmanager import GPU\n",
    "from PyHEADTAIL.general.contextmanager import CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define machine parameters and create a machine object and a corresponding matched bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Maximum RMS bunch length 0.117895128264m.\n",
      "... distance to target bunch length: 2.7183e-03\n",
      "... distance to target bunch length: 2.8426e-03\n",
      "... distance to target bunch length: 2.1082e-05\n",
      "... distance to target bunch length: 1.7265e-07\n",
      "... distance to target bunch length: 1.0978e-11\n",
      "--> Bunch length: 0.05\n",
      "--> Emittance: 0.163402650911\n"
     ]
    }
   ],
   "source": [
    "#  machine parameters\n",
    "circumference = 26658.8832\n",
    "n_segments = 10\n",
    "charge = e\n",
    "mass = m_p\n",
    "beta_x         = 92.7 \n",
    "D_x            = 0\n",
    "beta_y         = 93.2 \n",
    "D_y            = 0 \n",
    "\n",
    "Q_x            = 64.28\n",
    "Q_y            = 59.31\n",
    "\n",
    "Qp_x           = 10.\n",
    "Qp_y           = 15.\n",
    "\n",
    "app_x          = 0.0000e-9\n",
    "app_y          = 0.0000e-9\n",
    "app_xy         = 0\n",
    "\n",
    "alpha             = 3.225e-04\n",
    "\n",
    "h1, h2       = 35640, 35640*2\n",
    "V1, V2       = 6e6, 0.\n",
    "dphi1, dphi2 = 0, np.pi\n",
    "\n",
    "\n",
    "longitudinal_mode = 'non-linear'\n",
    "p0 = 450e9 * e / c\n",
    "p_increment = 0\n",
    "\n",
    "machine = BasicSynchrotron(\n",
    "    optics_mode='smooth', circumference=circumference, n_segments=n_segments, \n",
    "    beta_x=beta_x, D_x=D_x, beta_y=beta_y, D_y=D_y,\n",
    "    accQ_x=Q_x, accQ_y=Q_y, Qp_x=Qp_x, Qp_y=Qp_y, app_x=app_x, app_y=app_y, app_xy=app_xy,\n",
    "    alpha_mom_compaction=alpha, longitudinal_mode='non-linear',\n",
    "    h_RF=[h1,h2], V_RF=[V1,V2], dphi_RF=[dphi1,dphi2], p0=p0, p_increment=p_increment, charge=charge, mass=mass,\n",
    "    use_cython=False\n",
    ")\n",
    "\n",
    "### bunch parameters\n",
    "macroparticlenumber = 100000\n",
    "intensity = 1e11\n",
    "epsn_x  = 2.5e-6\n",
    "epsn_y  = 3.5e-6\n",
    "sigma_z = 0.05\n",
    "bunch   = machine.generate_6D_Gaussian_bunch_matched(\n",
    "    macroparticlenumber, intensity, epsn_x, epsn_y, sigma_z=sigma_z\n",
    ")\n",
    "\n",
    "# simulation parameters\n",
    "n_turns = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main tracking loop\n",
    "Up to this point everything has been performed on the CPU and the script for CPUs and GPUs is the same except the use_cython=False parameter when setting up the machine and the import pycuda.autoinit statement. Next, we'll create a GPU context to enclose the main tracking loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with GPU(bunch) as context:\n",
    "    for n in xrange(n_turns):\n",
    "        machine.track(bunch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this seems to work. How do we know it's actually running on the GPU? We can check the type of the bunch phase-space arrays inside of the with statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of bunch.x before entering the with-statement is  <type 'numpy.ndarray'>\n",
      "The type of bunch.x inside of the with-statement is  <class 'pycuda.gpuarray.GPUArray'>\n",
      "The type of bunch.x after the with-region is  <type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print 'The type of bunch.x before entering the with-statement is ', type(bunch.x)\n",
    "with GPU(bunch) as context:\n",
    "        machine.track(bunch)\n",
    "        print 'The type of bunch.x inside of the with-statement is ', type(bunch.x)\n",
    "print 'The type of bunch.x after the with-region is ', type(bunch.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the CPU contextmanager to have more similar code for GPU and CPU scripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of bunch.x before entering the with-statement is  <type 'numpy.ndarray'>\n",
      "The type of bunch.x inside of the with-statement is  <type 'numpy.ndarray'>\n",
      "The type of bunch.x after the with-region is  <type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print 'The type of bunch.x before entering the with-statement is ', type(bunch.x)\n",
    "with CPU(bunch) as context:\n",
    "        machine.track(bunch)\n",
    "        print 'The type of bunch.x inside of the with-statement is ', type(bunch.x)\n",
    "print 'The type of bunch.x after the with-region is ', type(bunch.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! If you need access to the bunch-phase space arrays during the simulation, you can move a copy back to the CPU by using bunch.x.get(). Printing GPUArrays works out of the box if you need it for debugging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of bunch.x inside of the with-statement is  <class 'pycuda.gpuarray.GPUArray'>\n",
      "The first three entries of bunch.x are  [-0.00019325 -0.00037008]\n",
      "A CPU copy of bunch.x inside the with-statement has type  <type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "with GPU(bunch) as context:\n",
    "    print 'The type of bunch.x inside of the with-statement is ', type(bunch.x)\n",
    "    print 'The first three entries of bunch.x are ', bunch.x[0:2]\n",
    "    cpu_bunch_x = bunch.x.get()\n",
    "    print 'A CPU copy of bunch.x inside the with-statement has type ', type(cpu_bunch_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
